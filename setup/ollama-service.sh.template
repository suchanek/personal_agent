#!/bin/bash
################################################################################
# Ollama Service Manager
#
# Manage the Ollama service running at user level
# Generated during Personal Agent installation
################################################################################

SCRIPT_NAME="start_ollama.sh"
SCRIPT_PATH="$HOME/.local/bin/$SCRIPT_NAME"
LOG_DIR="$HOME/Library/Logs/ollama"
MODELS_DIR="__OLLAMA_MODELS_DIR__"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

show_status() {
    echo -e "${BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"
    echo -e "${BLUE}Ollama Service Status${NC}"
    echo -e "${BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"
    echo ""
    
    # Check if process is running
    if pgrep -f "ollama serve" > /dev/null; then
        echo -e "${GREEN}✓${NC} Ollama is running"
        PID=$(pgrep -f "ollama serve")
        echo "  PID: $PID"
    else
        echo -e "${RED}✗${NC} Ollama is not running"
    fi
    
    # Check API
    if curl -s http://localhost:11434/api/version > /dev/null 2>&1; then
        VERSION=$(curl -s http://localhost:11434/api/version | jq -r '.version' 2>/dev/null || echo "unknown")
        echo -e "${GREEN}✓${NC} API is responding (version: $VERSION)"
    else
        echo -e "${RED}✗${NC} API is not responding"
    fi
    
    # Check models directory
    if [ -d "$MODELS_DIR" ]; then
        MODEL_COUNT=$(find "$MODELS_DIR" -name "*.gguf" 2>/dev/null | wc -l | tr -d ' ')
        echo -e "${GREEN}✓${NC} Models directory accessible ($MODEL_COUNT GGUF files)"
    else
        echo -e "${RED}✗${NC} Models directory not found: $MODELS_DIR"
    fi
    
    echo ""
    echo "Configuration:"
    echo "  Host: 0.0.0.0:11434"
    echo "  Models: $MODELS_DIR"
    echo "  Logs: $LOG_DIR/"
    echo "  RAM Optimization: __KV_CACHE_TYPE__ cache, max __MAX_LOADED_MODELS__ models"
    echo ""
}

start_service() {
    if pgrep -f "ollama serve" > /dev/null; then
        echo -e "${YELLOW}⚠${NC} Ollama is already running"
        return 0
    fi
    
    echo "Starting Ollama service..."
    nohup "$SCRIPT_PATH" > "$LOG_DIR/startup.log" 2>&1 &
    sleep 3
    
    if pgrep -f "ollama serve" > /dev/null; then
        echo -e "${GREEN}✓${NC} Ollama started successfully"
    else
        echo -e "${RED}✗${NC} Failed to start Ollama"
        echo "Check logs: tail -f $LOG_DIR/ollama.err.log"
        return 1
    fi
}

stop_service() {
    if ! pgrep -f "ollama serve" > /dev/null; then
        echo -e "${YELLOW}⚠${NC} Ollama is not running"
        return 0
    fi
    
    echo "Stopping Ollama service..."
    pkill -f "ollama serve"
    sleep 2
    
    if ! pgrep -f "ollama serve" > /dev/null; then
        echo -e "${GREEN}✓${NC} Ollama stopped successfully"
    else
        echo -e "${RED}✗${NC} Failed to stop Ollama gracefully, forcing..."
        pkill -9 -f "ollama serve"
    fi
}

restart_service() {
    stop_service
    sleep 1
    start_service
}

show_logs() {
    local log_type="${1:-out}"
    if [ "$log_type" = "err" ]; then
        tail -f "$LOG_DIR/ollama.err.log"
    else
        tail -f "$LOG_DIR/ollama.out.log"
    fi
}

list_models() {
    echo "Available models:"
    curl -s http://localhost:11434/api/tags | jq -r '.models[].name' 2>/dev/null || echo "Failed to fetch models (is Ollama running?)"
}

case "${1:-status}" in
    start)
        start_service
        ;;
    stop)
        stop_service
        ;;
    restart)
        restart_service
        ;;
    status)
        show_status
        ;;
    logs)
        show_logs "${2:-out}"
        ;;
    models)
        list_models
        ;;
    *)
        echo "Usage: $0 {start|stop|restart|status|logs [out|err]|models}"
        exit 1
        ;;
esac
