# Personal AI Agent Environment Variables
# Copy this file to .env and fill in your actual API keys

# GitHub Personal Access Token
# Get from: https://github.com/settings/tokens
GITHUB_PERSONAL_ACCESS_TOKEN=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

# Brave Search API Key  
# Get from: https://api.search.brave.com/app/keys
BRAVE_API_KEY=BSAzjAuPynpGtJHeUF3S3a60wQEXYHx

# MULTIMODAL AGENTS: API Keys for Media Generation
# ModelsLab API Key
# Get from: https://modelslab.com/
MODELS_LAB_API_KEY="2CodpwR1aAjtJFDOef9lLCcXiDYnMwmOIQCqg3df0Cczr6NVI1eHWFgwuYSB"

# ElevenLabs API Key  
# Get from: https://elevenlabs.io/
ELEVEN_LABS_API_KEY="sk_c8819b6bbc638a5b7f0a64e7db5ea6f11950c8581d414e10"

# Giphy API Key
# Get from: https://developers.giphy.com/
GIPHY_API_KEY="17TZYF4BFE16Bcxlo5HmSP6ZKTttJwkm"

# Directories for the Personal AI Agent
ROOT_DIR=/                     # Full filesystem access
HOME_DIR=/Users/egs           # User's home directory  
DATA_DIR=/Users/egs/data      # Data directory for vector database
REPO_DIR=/Users/egs/repos     # Repository directory

# Core Agent Configuration
WEAVIATE_URL=http://localhost:8080
REMOTE_OLLAMA_URL=http://tesla.local:11434

#OLLAMA_URL=http://tesla.local:11434
OLLAMA_URL=http://localhost:11434

USE_WEAVIATE=False
USE_MCP=True
LOG_LEVEL=INFO
# LLM Model configuration - use actual model names, not dictionary references
#LLM_MODEL=llama3.1:8b-instruct-q8_0
LLM_MODEL=qwen3:1.7b


# Agno Storage Configuration
# Storage backend: "weaviate" or "agno"
STORAGE_BACKEND=agno
AGNO_STORAGE_DIR=${DATA_DIR}/${STORAGE_BACKEND}

# Knowledge directory for Agno
AGNO_KNOWLEDGE_DIR=${DATA_DIR}/knowledge

# USER CONFIGURATION
USER_ID="Eric"

# MODEL CONTEXT SIZE OVERRIDES
# Override context sizes for specific models (optional)
# Format: MODEL_NAME_CTX_SIZE (replace : with _ and . with _)
# Examples:
# QWEN3_1_7B_CTX_SIZE=16384
# LLAMA3_1_8B_INSTRUCT_Q8_0_CTX_SIZE=65536
# DEFAULT_MODEL_CTX_SIZE=8192

# RATE LIMITING CONFIGURATION
# DuckDuckGo Search Rate Limiting
DUCKDUCKGO_SEARCH_DELAY=3.0      # Seconds between search requests
DUCKDUCKGO_MAX_RETRIES=3         # Maximum retries on rate limit
DUCKDUCKGO_RETRY_DELAY=10.0      # Base retry delay (exponential backoff)

# Default API Rate Limiting (for other tools)
DEFAULT_API_DELAY=1.0            # Default delay between API calls
DEFAULT_MAX_RETRIES=3            # Default maximum retries
DEFAULT_RETRY_DELAY=5.0          # Default retry delay


# LIGHTRAG CONFIGURATION (fully reusing DATA_DIR)

# LLM configuration for LightRAG
LLM_TYPE=ollama
LLM_MODEL_LIGHRAG=mistral:latest

# Embedding model (also via Ollama)
EMBEDDING_TYPE=ollama
EMBEDDING_MODEL=nomic-embed-text

# Vector DB backend for LightRAG (isolated LanceDB inside data/lightrag)
VECTOR_STORE=lancedb://${DATA_DIR}/lightrag/lancedb

# Knowledge graph storage backend for LightRAG
GRAPH_STORE=sqlite://${DATA_DIR}/lightrag/lightrag_graph.db

# Optional LightRAG REST server configuration
SERVER_PORT=8000
SERVER_HOST=0.0.0.0
