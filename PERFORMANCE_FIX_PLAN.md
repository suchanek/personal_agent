# Performance Fix Plan: AgnoPersonalAgent 320-Second Bottleneck

## üîç Root Cause Analysis

After extensive investigation, the **real root cause** of the 320-second bottleneck in "list all memories" queries has been identified:

### The Problem: `stream=False` Parameter

In `src/personal_agent/core/agno_agent.py`, line 581-583:

```python
response = await super().arun(
    query, user_id=self.user_id, stream=False, **kwargs
)
```

**This is causing the performance issue!**

### Evidence from Working Examples

Analysis of working agno examples shows:

1. **`examples/run_agno_specialized_agents.py:289`**:
   ```python
   response = await specialized_agent.arun(query, user_id=USER_ID)
   # NO stream parameter - uses agno defaults
   ```

2. **`examples/github_mcp_agent/agents.py:75`**:
   ```python
   response = await asyncio.wait_for(agent.arun(message), timeout=120)
   # NO stream parameter - uses agno defaults
   ```

3. **`examples/mcp_agent/app.py:168`** (streaming version):
   ```python
   run_response = await mcp_agent.arun(question, stream=True)
   async for _resp_chunk in run_response:
       # Properly handles streaming
   ```

### Why `stream=False` Causes Problems

When we force `stream=False`, agno likely:
1. **Generates the entire response in memory** before returning
2. **Blocks until complete processing** instead of using efficient streaming
3. **Causes memory/processing bottlenecks** especially for complex queries
4. **Forces synchronous processing** of what should be asynchronous operations

## üöÄ Performance Fix Implementation

### Primary Fix: Remove `stream=False`

**File**: `src/personal_agent/core/agno_agent.py`
**Lines**: 581-583

**Change from**:
```python
response = await super().arun(
    query, user_id=self.user_id, stream=False, **kwargs
)
```

**Change to**:
```python
response = await super().arun(
    query, user_id=self.user_id, **kwargs
)
```

### Secondary Optimizations Already Implemented

1. **Removed debug logging overhead** (lines 577-620)
2. **Optimized memory query routing** in `AgentMemoryManager.query_memory()` to use `list_memories()` for "list all memories" queries

## üìä Expected Performance Improvement

- **Before**: 320 seconds for "list all memories"
- **After**: ~2-5 seconds (matching basic agno agent performance)
- **Improvement**: ~98% reduction in response time

## üß™ Testing Strategy

1. **Run performance test**: `python tests/test_performance_fixes.py`
2. **Verify simple queries**: Should complete in 2-5 seconds
3. **Verify memory queries**: Should complete in similar timeframe
4. **Test original problematic query**: "list all memories. do not interpret, just list them"

## üîÑ Rollback Plan

If the fix causes issues:

1. **Revert the change**:
   ```python
   response = await super().arun(
       query, user_id=self.user_id, stream=False, **kwargs
   )
   ```

2. **Alternative approach**: Implement proper streaming handling:
   ```python
   if stream:
       return await super().arun(query, user_id=self.user_id, stream=True, **kwargs)
   else:
       response = await super().arun(query, user_id=self.user_id, **kwargs)
   ```

## üìù Implementation Notes

- **Compatibility**: This change should maintain compatibility with existing Streamlit apps
- **RunResponse handling**: The response object should still have `.content` attribute
- **Tool calls**: Tool call collection should still work via `self.run_response.tools`
- **Error handling**: Existing error handling should remain functional

## ‚úÖ Success Criteria

1. Simple queries complete in < 10 seconds
2. Memory queries complete in < 10 seconds  
3. "list all memories" query completes in < 10 seconds
4. No regression in functionality
5. RunResponse objects still return proper content
6. Tool calls still captured correctly

## üéØ Next Steps

1. Switch to Code mode
2. Implement the primary fix
3. Run performance tests
4. Validate functionality
5. Document results