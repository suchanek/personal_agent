# ADR-059: Refactor Tool Extraction and Response Handling

## Status

Accepted

## Context

The existing implementation for handling agent and team responses, particularly for extracting tool calls and their results, had several limitations:

1.  **Inconsistent Tool Call Objects**: Different models and agent configurations produced tool call objects with varying structures (e.g., using `name`, `tool_name`, or `function.name` for the tool's name). This led to complex and brittle extraction logic.
2.  **Streamlit UI Bugs**: The Streamlit application had several bugs related to response handling:
    *   It would sometimes display the raw tool call syntax (e.g., `write_original_content(...)`) instead of the actual content generated by the writer agent.
    *   It failed to correctly handle `agent.arun()` with asynchronous tools in single-agent mode, causing crashes.
    *   Tool call information was not consistently displayed, especially in team-based scenarios.
3.  **Team Routing Issues**: The `personal_agent_team` was configured in `route` mode, which was not effectively delegating tasks to the specialized agents. The coordinator often failed to select the correct agent or returned a tool call instead of the executed result.
4.  **Tool Naming**: The `AgnoMemoryTools` and `KnowledgeTools` were not clearly named to indicate their purpose within the `persag` (personal agent) context.

These issues were degrading the user experience and making it difficult to debug agent behavior.

## Decision

We decided to undertake a significant refactoring of the response handling and tool extraction logic across the application. The key changes are:

1.  **Unified Tool Call Extraction**:
    *   Created a new, robust `extract_tool_calls_and_metrics` function in `paga_streamlit_agno.py`.
    *   This function handles multiple tool call formats (objects and dictionaries) and gracefully extracts the tool name, arguments, and results from various structures.
    *   It now correctly processes responses from both single agents and teams, including nested tool calls from member agents in `coordinate` mode.

2.  **Streamlit UI Fixes**:
    *   The Streamlit chat interface now uses `agent.arun()` for single-agent mode, which correctly handles asynchronous tools.
    *   A new response handling logic was added to the Streamlit app to detect when a writer agent's response contains a tool call. In such cases, it now extracts the *actual* content from the member agent's response, ensuring the user sees the final generated text.
    *   The tool call display has been enhanced to show the source of the tool call (coordinator or a specific member agent).

3.  **Team Delegation and Reasoning**:
    *   The `personal_agent_team` mode was changed from `route` to `coordinate`.
    *   `ReasoningTools` were added to the team coordinator to improve its ability to delegate tasks to the correct specialized agent.
    *   The writer agent's `show_tool_calls` was enabled to ensure its tool executions are visible to the team coordinator.

4.  **Tool Renaming**:
    *   `AgnoMemoryTools` was renamed to `PersagMemoryTools` to better reflect its role as the personal agent's memory system.
    *   `KnowledgeTools` was renamed to `PersagKnowledgeTools` for consistency.

5.  **Testing**:
    *   Added several new test scripts to validate these fixes:
        *   `test_tool_call_extraction.py`: Verifies the new unified extraction logic.
        *   `test_dict_tool_call_extraction.py`: Specifically tests dictionary-based tool call formats.
        *   `test_streamlit_arun_fix.py`: Confirms that `agent.arun()` works correctly with async tools.
        *   `test_streamlit_writer_fix.py`: Validates that the writer agent's content is correctly extracted and displayed.
        *   `test_team_routing_debug.py`: A debug script to analyze and confirm team delegation.

## Consequences

### Positive

*   **Improved Reliability**: The agent and Streamlit UI are now more robust and less prone to errors related to response parsing.
*   **Better User Experience**: The Streamlit app now correctly displays generated content and provides clearer insight into tool usage.
*   **Enhanced Debugging**: The improved tool call extraction and logging make it easier to understand and debug agent behavior.
*   **More Effective Teams**: The team coordinator is now more effective at delegating tasks to the appropriate specialized agents.

### Negative

*   **Increased Complexity**: The new response handling logic is more complex, but this is a necessary trade-off for the increased reliability and functionality.
