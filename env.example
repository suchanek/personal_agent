# Personal AI Agent Environment Variables
# Minimal version - only essential overrides

# =============================================================================
# BASIC CONFIGURATION
# =============================================================================
DEBUG = 10
INFO = 20
WARNING = 30
ERROR = 40

LOG_LEVEL=INFO

# =============================================================================
# DIRECTORY CONFIGURATION
# =============================================================================

ROOT_DIR=/
HOME_DIR=/Users/egs 
REPO_DIR=${HOME_DIR}/repos

# =============================================================================
# AI MODEL CONFIGURATION
# =============================================================================

PROVIDER="ollama"
REMOTE_OLLAMA_URL=http://100.100.248.61:11434

# =============================================================================
# AI MODEL CONFIGURATION
# =============================================================================

#LLM_MODEL=llama3.1:8b

LLM_MODEL=qwen3:8b

#LLM_MODEL=qwen3-8b-mlx-4bit
#LLM_MODEL=mistral-nemo:latest
#LLM_MODEL=qwen3:8b
#LLM_MODEL="myaniu/qwen2.5-1m:latest"

# =============================================================================
# API Access tokens - secret
# =============================================================================

# GitHub Personal Access Token
GITHUB_PERSONAL_ACCESS_TOKEN=yourtoken
# GitHub Token (for Agno GithubTools)
GITHUB_TOKEN=yourtoken
# GitHub Access Token (alternative name)
GITHUB_ACCESS_TOKEN=yourtoken

# Brave Search API Key  
BRAVE_API_KEY=yourtoken

# MULTIMODAL AGENTS: API Keys for Media Generation
MODELS_LAB_API_KEY=yourtoken
ELEVEN_LABS_API_KEY=yourtoken
GIPHY_API_KEY=yourtoken
OPENAI_API_KEY=sk-proj-yourtoken

# =============================================================================
# NOTES
# =============================================================================
# All other variables use sensible defaults from settings.py:
# - WEAVIATE_URL=http://localhost:8080, OLLAMA_URL=http://localhost:11434
# - LIGHTRAG_URL=http://localhost:9621, LIGHTRAG_MEMORY_URL=http://localhost:9622
# - PORT=9621, LIGHTRAG_PORT=9621, LIGHTRAG_MEMORY_PORT=9622
# - USE_WEAVIATE=False, USE_MCP=True, SHOW_SPLASH_SCREEN=False
# - STORAGE_BACKEND=agno, EMBEDDING_MODEL=nomic-embed-text
# - All timeout settings have reasonable defaults for most use cases
